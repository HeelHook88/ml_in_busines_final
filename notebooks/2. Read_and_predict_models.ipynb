{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import dill\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix, log_loss\n",
    "import catboost as catb\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import jupyterthemes as jt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('C:/Users/Андрей/PycharmProjects/cource_proj_api/models/lightgbm_pipeline.dill', 'rb') as in_strm:\n",
    "    pipeline = dill.load(in_strm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = pipeline.predict(X_test)\n",
    "y_score = pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.400505, F-Score=0.789, Roc_auc=0.714, Log_loss=0.742, Precision=0.750, Recall=0.833\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "precision, recall, thresholds = precision_recall_curve(y_test['target'], y_score)\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "roc = roc_auc_score(y_test['target'], y_predict)\n",
    "log_los = log_loss(y_test['target'], y_score)\n",
    "\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Roc_auc=%.3f, Log_loss=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        roc,\n",
    "                                                                        log_los,\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]\n",
    "                                                                                     ))\n",
    "\n",
    "result.append({\"method\":\"light_gbm_PU_0.25\" ,\"roc_auc\" : roc, \"fscore\" : fscore[ix],\n",
    "               \"precision\" : precision[ix], \"recall\" : recall[ix],\n",
    "               \"log_los\" : log_los\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
